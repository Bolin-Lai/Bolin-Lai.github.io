<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>Bolin Lai</title>

    <meta name="author" content="Bolin Lai">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="shortcut icon" href="images/favicon/favicon.ico" type="image/x-icon">
    <link rel="stylesheet" type="text/css" href="stylesheet.css">
    
  </head>

  <body>
    <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr style="padding:0px">
              <td style="padding:2.5%;width:60%;vertical-align:middle">
                <p class="name" style="text-align: center;">Bolin Lai</p>
                <p>Hi! I am a third-year PhD student in the Machine Learning Program of Georgia Institute of Technology, advised by <a href="https://rehg.org/">Prof. James Rehg</a> and co-advised by <a href="https://faculty.cc.gatech.edu/~zk15/">Prof. Zsolt Kira</a>. Prior to starting my PhD, I got my Master's degree majoring in ECE and Bachelor's degree majoring in Information Engineering from Shanghai Jiao Tong University. I worked with <a href="https://scholar.google.com/citations?user=pbjw9sMAAAAJ&hl=en&oi=ao">Prof. Ya Zhang</a> during my master.</p>
                <p>My research interests lie in <b>Video Understanding</b>, <b>Multi-Modal Learning</b> and general machine learning algorithms. Currently, I'm working on egocentric video understanding and diffusion models.</p>
                <p style="text-align:center">
                  <a href="bolin.lai@gatech.edu">Email</a> &nbsp;/&nbsp;
                  <a href="https://scholar.google.com/citations?user=lWrljmQAAAAJ&hl=en"> Google Scholar</a> &nbsp;/&nbsp;
                  <a href="https://github.com/BolinLai">Github</a> &nbsp;/&nbsp;
                  <a href="https://www.linkedin.com/in/bolin-lai-625b78139">LinkedIn</a> &nbsp;/&nbsp;
                  <a href="https://twitter.com/bryanislucky">Twitter</a>
                </p>
              </td>
              <td style="padding:2.5%;width:35%;max-width:40%">
                <img style="width:100%;max-width:100%;object-fit:cover;" alt="profile photo" src="figures/photo.png">
                <!-- <img style="width:100%;max-width:100%;object-fit:cover;border-radius: 50%;" alt="profile photo" src="figures/photo.png"> -->
              </td>
            </tr>
          </tbody></table>

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
              <td style="padding:20px;width:100%;vertical-align:middle">
                <h2>News</h2>
              </td>
            </tr>

            <tr>
              <td style="padding:5px;width:100%;vertical-align:middle">
                <ul>
                  <li>Jul 2023: Our expansion of prior work GLC was accepted by IJCV!</li>
                  <li>May 2023: I started my internship at GenAI Meta in Bay Area!</li>
                  <li>Apr 2023: I successfully passed the qualifying exam.</li>
                  <li>Mar 2023: One paper was accepted to the Findings of ACL2023.</li>
                  <li>Nov 2022: We won the Best Student Paper Prize on BMVC. Thanks for all co-authors!</li>
                  <li>Sep 2022: Our work <a href="https://bolinlai.github.io/GLC-EgoGazeEst/">GLC</a> was accepted by <a href="https://bmvc2022.org/">BMVC 2022</a>!</li>
                  <li>Jan 2022: I started working with <a href="https://rehg.org/">Prof. James Rehg</a> at Georgia Tech.</li>
                </ul>
              </td>
            </tr>
          </tbody></table>
          
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
              <td style="padding:20px;width:100%;vertical-align:middle">
                <h2>Publications</h2>
              </td>
            </tr>
          </tbody></table>
          
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
              <td style="padding:20px;width:40%;vertical-align:middle;">
                <div class="one">
                  <img src='figures/lego.png' width="100%">
                </div>
              </td>
              <td style="padding:20px;width:60%;vertical-align:middle;">
                <span class="papertitle">Listen to Look into the Future: Audio-Visual Egocentric Gaze Anticipation</span>
                <br>
                <br>
                <strong>Bolin Lai</strong>,
                <a href="https://sites.google.com/view/xiaoliangdai/">Xiaoliang Dai</a>,
                Lawrence Chen, Guan Pang,
                <a href="https://rehg.org/">James M. Rehg</a>,
                <a href="https://aptx4869lm.github.io/">Miao Liu</a>
                <br>
                <em>Preprint</em>
                <br>
                Project Page /
                <a href="https://arxiv.org/pdf/2312.03849.pdf">Paper</a> /
                Annotations / Code
              </td>
            </tr>
            
            <tr>
              <td style="padding:20px;width:40%;vertical-align:middle;">
                <div class="one">
                  <img src='figures/avgaze.png' width="90%">
                </div>
              </td>
              <td style="padding:20px;width:60%;vertical-align:middle;">
                <span class="papertitle">Listen to Look into the Future: Audio-Visual Egocentric Gaze Anticipation</span>
                <br>
                <br>
                <strong>Bolin Lai</strong>,
                <a href="https://fkryan.github.io/">Fiona Ryan</a>,
                <a href="https://vjwq.github.io/">Wenqi Jia</a>,
                <a href="https://aptx4869lm.github.io/">Miao Liu*</a>,
                <a href="https://rehg.org/">James M. Rehg*</a>
                <br>
                <em>Preprint</em>
                <br>
                Project Page /
                <a href="https://arxiv.org/pdf/2305.03907.pdf">Paper</a> /
                Annotations / Code
              </td>
            </tr>

            <tr>
              <td style="padding:20px;width:40%;vertical-align:middle">
                <div class="one">
                  <img src='figures/deduction.png' width="100%">
                </div>
              </td>
              <td style="padding:20px;width:60%;vertical-align:middle">
                <span class="papertitle">Werewolf Among Us: Multimodal Resources for Modeling Persuasion Behaviors in Social Deduction Games</span>
                <br>
                <br>
                <strong>Bolin Lai</strong>*,
                <a href="https://icefoxzhx.github.io/">Hongxin Zhang*</a>,
                <a href="https://aptx4869lm.github.io/">Miao Liu*</a>,
                Aryan Pariani*,
                <a href="https://fkryan.github.io/">Fiona Ryan</a>,
                <a href="https://vjwq.github.io/">Wenqi Jia</a>,
                <a href="https://www.shirley.id/">Shirley Anugrah Hayati</a>,
                <a href="https://rehg.org/">James M. Rehg</a>,
                <a href="https://cs.stanford.edu/~diyiy/">Diyi Yang</a>
                <br>
                <font color='#A51014'><em>ACL Findings</em>, 2023</font>
                <br>
                <a href="https://persuasion-deductiongame.socialai-data.org/">Project Page</a> /
                <a href="https://aclanthology.org/2023.findings-acl.411.pdf">Paper</a> /
                <a href="https://drive.google.com/drive/folders/1N4PymMbKXFzqy3fq4ZGjdrc0oiScV914">Dataset</a> /
                <a href="https://github.com/SALT-NLP/PersuationGames">Code</a>
                <!-- <p>Modeling social behaviors of multi-person scenarios using both video and language.</p> -->
              </td>
            </tr>

            <tr>
              <td style="padding:20px;width:40%;vertical-align:middle">
                <div class="one">
                  <img src='figures/glc.png' width="100%">
                </div>
              </td>
              <td style="padding:20px;width:60%;vertical-align:middle">
                <span class="papertitle">In the Eye of Transformer: Global-Local Correlation for Egocentric Gaze Estimation</span>
                <br>
                <br>
                <strong>Bolin Lai</strong>,
                <a href="https://aptx4869lm.github.io/">Miao Liu</a>,
                <a href="https://fkryan.github.io/">Fiona Ryan</a>,
                <a href="https://rehg.org/">James M. Rehg</a>
                <br>
                <font color='#A51014'><em>BMVC</em>, 2022 (Best Student Paper)</font>
                <br>
                <a href="https://bolinlai.github.io/GLC-EgoGazeEst/">Project Page</a> /
                <a href="https://bmvc2022.mpi-inf.mpg.de/0227.pdf">Paper</a> /
                <a href="https://bmvc2022.mpi-inf.mpg.de/0227_supp.zip">Supplement</a> /
                <a href="https://bolinlai.github.io/GLC-EgoGazeEst/Ego4D_Gaze_Split.zip">Data Split</a> /
                <a href="https://github.com/BolinLai/GLC">Code</a> /
                <a href="https://bmvc2022.mpi-inf.mpg.de/0227_video.mp4">Video</a> /
                <a href="https://bmvc2022.mpi-inf.mpg.de/0227_poster.pdf">Poster</a>
                <!-- <p>Improving egocentric gaze estimation by explicitly modeling global-local correlations in transformer-based architecture.</p> -->
                <br>
                <br>
                <span class="papertitle">In the Eye of Transformer: Global-Local Correlation for Egocentric Gaze Estimation and Beyond</span>
                <br>
                <br>
                <strong>Bolin Lai</strong>,
                <a href="https://aptx4869lm.github.io/">Miao Liu</a>,
                <a href="https://fkryan.github.io/">Fiona Ryan</a>,
                <a href="https://rehg.org/">James M. Rehg</a>
                <br>
                <font color='#A51014'><em>IJCV</em>, 2023</font> (Expansion of the BMVC work)
                <br>
                <a href="https://link.springer.com/article/10.1007/s11263-023-01879-7">Paper</a>
              </td>
            </tr>
          </tbody></table>

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
                <td style="padding:20px;width:100%;vertical-align:middle">
                  ---------------- Research before my PhD, mainly about medical image analysis ----------------
                </td>
              </tr>
          </tbody></table>

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
              <td style="padding:20px;width:40%;vertical-align:middle">
                <div class="one">
                  <img src='figures/venibot.png' width="100%">
                </div>
              </td>
              <td style="padding:20px;width:60%;vertical-align:middle">
                <span class="papertitle">Semi-supervised Vein Segmentation of Ultrasound Images for Autonomous Venipuncture</span>
                <br>
                <br>
                Yu Chen, Yuxuan Wang, <strong>Bolin Lai</strong>, Zijie Chen, Xu Cao,
                <a href="https://ynysjtu.github.io/">Nanyang Ye</a>,
                Zhongyuan Ren, Junbo Zhao, 
                <a href="https://xiaoyunzhou27.github.io/xiaoyunzhou/">Xiao-Yun Zhou</a>,
                <a href="https://nms.kcl.ac.uk/core/?page_id=44">Peng Qi</a>
                <br>
                <font color='#A51014'><em>IROS</em>, 2021</font>
                <br>
                [<a href="https://arxiv.org/pdf/2105.12945">Paper</a>]
              </td>
            </tr>

            <tr>
              <td style="padding:20px;width:40%;vertical-align:middle">
                <div class="one">
                  <img src='figures/semi_tumor.png' width="100%">
                </div>
              </td>
              <td style="padding:20px;width:60%;vertical-align:middle">
                <span class="papertitle">Hetero-Modal Learning and Expansive Consistency Constraints for Semi-Supervised Detection from Multi-Sequence Data</span>
                <br>
                <br>
                <strong>Bolin Lai</strong>, Yuhsuan Wu, 
                <a href="https://xiaoyunzhou27.github.io/xiaoyunzhou/">Xiao-Yun Zhou</a>,
                Peng Wang,
                <a href="https://lelu007.github.io/">Le Lu</a>,
                Lingyun Huang,
                Mei Han, Jing Xiao, Heping Hu, 
                <a href="https://extragoya.github.io/">Adam P. Harrison</a>
                <br>
                <font color='#A51014'><em>Machine Learning in Medical Imaging</em>, 2021</font>
                <br>
                [<a href="https://arxiv.org/pdf/2103.12972.pdf">Paper</a>]
              </td>
            </tr>

            <tr>
              <td style="padding:20px;width:40%;vertical-align:middle">
                <div class="one">
                  <img src='figures/ksp.png' width="100%">
                </div>
              </td>
              <td style="padding:20px;width:60%;vertical-align:middle">
                <span class="papertitle">Liver Tumor Localization and Characterization from Multi-phase MR Volumes Using Key-Slice Prediction: A Physician-Inspired Approach</span>
                <br>
                <br>
                <strong>Bolin Lai</strong>*, Yuhsuan Wu*, Xiaoyu Bai*,
                <a href="https://xiaoyunzhou27.github.io/xiaoyunzhou/">Xiao-Yun Zhou</a>,
                Peng Wang,
                <a href="https://jimmycai91.github.io/">Jinzheng Cai</a>,
                <a href="https://hrlblab.github.io/">Yuankai Huo</a>,
                Lingyun Huang,
                <a href="https://jszy.nwpu.edu.cn/en/yongxia.html">Yong Xia</a>,
                Jing Xiao,
                <a href="https://lelu007.github.io/">Le Lu</a>,
                Heping Hu,
                <a href="https://extragoya.github.io/">Adam P. Harrison</a>
                <br>
                <font color='#A51014'><em>International Workshop on PRedictive Intelligence In MEdicine</em>, 2021</font>
                <br>
                [<a href="https://www.researchgate.net/profile/Adam-Harrison-6/publication/354887409_Liver_Tumor_Localization_and_Characterization_from_Multi-phase_MR_Volumes_Using_Key-Slice_Prediction_A_Physician-Inspired_Approach/links/61def5ba4e4aff4a643863ea/Liver-Tumor-Localization-and-Characterization-from-Multi-phase-MR-Volumes-Using-Key-Slice-Prediction-A-Physician-Inspired-Approach.pdf">Paper</a>]
              </td>
            </tr>

            <tr>
              <td style="padding:20px;width:40%;vertical-align:middle">
                <div class="one">
                  <img src='figures/spinal_dislocation.png' width="100%">
                </div>
              </td>
              <td style="padding:20px;width:60%;vertical-align:middle">
                <span class="papertitle">Spatial Regularized Classification Network for Spinal Dislocation Diagnosis</span>
                <br>
                <br>
                <strong>Bolin Lai</strong>, Shiqi Peng, Guangyu Yao,
                <a href="https://scholar.google.com/citations?user=pbjw9sMAAAAJ&hl=en&oi=ao">Ya Zhang</a>,
                Xiaoyun Zhang, Yanfeng Wang, Hui Zhao
                <br>
                <font color='#A51014'><em>Machine Learning in Medical Imaging</em>, 2019</font>
                <br>
                [<a href="https://www.researchgate.net/profile/Adam-Harrison-6/publication/354887409_Liver_Tumor_Localization_and_Characterization_from_Multi-phase_MR_Volumes_Using_Key-Slice_Prediction_A_Physician-Inspired_Approach/links/61def5ba4e4aff4a643863ea/Liver-Tumor-Localization-and-Characterization-from-Multi-phase-MR-Volumes-Using-Key-Slice-Prediction-A-Physician-Inspired-Approach.pdf">Paper</a>]
              </td>
            </tr>
          </tbody></table>

          <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
            <tr>
              <td>
                <h2>Service</h2>
              </td>
            </tr>
          </tbody></table>

          <table width="100%" align="center" border="0" cellpadding="20"><tbody>
            <tr>
              <td width="100%" valign="center">
                Reviewer for CVPR, AAAI, MICCAI, JBHI, SPL.
              </td>
            </tr>
          </tbody></table>

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
              <td style="padding:0px">
                <br>
                <p style="text-align:right;font-size:small;">
                  This website is adapted from this <a href="https://github.com/jonbarron/jonbarron_website">source code</a>.
                </p>
              </td>
            </tr>
          </tbody></table>

        </td>
      </tr>
    </table>
  </body>
</html>
